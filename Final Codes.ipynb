{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656bcad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense , Dropout\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca77cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root => where to pick the data/folder\n",
    "root = 'MyData'\n",
    "\n",
    "# dest => where to store the output data \n",
    "dest = 'D:\\\\Educational\\Sign Language Recognition\\MyData processed'\n",
    "\n",
    "# looping over root directory's subdirectories\n",
    "for enter in os.listdir(root):\n",
    "    \n",
    "    # specifying the final destination\n",
    "    final = os.path.join(dest,enter)\n",
    "    path = os.path.join(root,enter)\n",
    "    \n",
    "    # making the target/final directory\n",
    "    os.makedirs(final)\n",
    "    \n",
    "    for item in os.listdir(path):\n",
    "        \n",
    "        # reading image from specified source\n",
    "        image = cv2.imread(os.path.join(path,item),1)\n",
    "        \n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray,(5,5),2)\n",
    "        th3 = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,11,2)\n",
    "        ret, res = cv2.threshold(th3, 70, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "        #Saving the image \n",
    "        name = os.path.join(final,item)\n",
    "        cv2.imwrite(name ,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d1f5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sz = 128\n",
    "train = r'C:\\\\Users\\Dhruv\\Downloads\\train\\train'\n",
    "test = r'C:\\\\Users\\Dhruv\\Downloads\\test\\test'\n",
    "classifier = Sequential()\n",
    "\n",
    "# First convolution layer and pooling\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape=(sz, sz, 1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Second convolution layer and pooling\n",
    "classifier.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "# Flattening the layers\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Adding a fully connected layer\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dropout(0.40))\n",
    "classifier.add(Dense(units=96, activation='relu'))\n",
    "classifier.add(Dropout(0.40))\n",
    "classifier.add(Dense(units=64, activation='relu'))\n",
    "classifier.add(Dense(units=27, activation='softmax')) # softmax for more than 2\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # categorical_crossentropy for more than 2\n",
    "\n",
    "\n",
    "# Step 2 - Preparing the train/test data and training the model\n",
    "classifier.summary()\n",
    "# Code copied from - https://keras.io/preprocessing/image/\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train,\n",
    "                                                 target_size=(sz, sz),\n",
    "                                                 batch_size=10,\n",
    "                                                 color_mode='grayscale',\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test,\n",
    "                                            target_size=(sz , sz),\n",
    "                                            batch_size=10,\n",
    "                                            color_mode='grayscale',\n",
    "                                            class_mode='categorical')\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"Best-Model-.h5\",save_best_only =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c901c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=1284, # No of images in training set\n",
    "        epochs=50,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=426,\n",
    "        callbacks = [checkpoint_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2d99d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W']\n",
      "W\n"
     ]
    }
   ],
   "source": [
    "SemodelImport = keras.models.load_model(\"C:\\\\Users\\\\Dhruv\\\\Downloads\\\\Best-Model-iit.h5\")\n",
    "label = [\" \",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"]\n",
    "engine = pyttsx3.init()\n",
    "vid = cv2.VideoCapture(0)\n",
    "img1 = np.zeros((500,500,3),np.uint8)\n",
    "out = ''\n",
    "while(vid.isOpened()):\n",
    "    ret,frame = vid.read()\n",
    "#     cv2.rectangle(frame,(100,100),(400,400),(0,255,0),1)\n",
    "    cv2.imshow(\"Image\",frame)\n",
    "    cv2.imshow(\"Text\",img1)\n",
    "    crop = frame[100:400, 100:400]\n",
    "    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),2)\n",
    "    th3 = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,11,2)\n",
    "    ret, res = cv2.threshold(th3, 70, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    cv2.imshow(\"crop\",res)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k != -1:\n",
    "        if k==27:\n",
    "            break\n",
    "        else:\n",
    "            cv2.imwrite(\"test.jpg\",res)\n",
    "            image = tf.keras.preprocessing.image.load_img(\"test.jpg\",grayscale=True ,target_size = (128,128))\n",
    "            image_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "            image_arr = np.array([image_arr])\n",
    "            pred = SemodelImport.predict_classes(image_arr)\n",
    "            print(np.array(label)[pred])\n",
    "            out = out + (str(np.array(label)[pred]))[2]\n",
    "            cv2.putText(img1,out,(100,100),cv2.FONT_HERSHEY_SIMPLEX,0.6, (255,255,255), 1)\n",
    "          \n",
    "print(out)\n",
    "vid.release()\n",
    "cv2.destroyAllWindows() \n",
    "engine.setProperty('rate',100) #determine the rate of speech (optional)/ used for changing rate of speech\n",
    "engine.say(out) #\n",
    "engine.runAndWait() # the code will wait for the speech to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9d2aec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H']\n",
      "['E']\n",
      "['L']\n",
      "['L']\n",
      "['O']\n"
     ]
    }
   ],
   "source": [
    "SemodelImport = keras.models.load_model(\"Best-Model-iit.h5\")\n",
    "out = ''\n",
    "engine = pyttsx3.init()\n",
    "label = [\" \",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"]\n",
    "for i in range(1,6):\n",
    "    image = tf.keras.preprocessing.image.load_img(str(i)+\".jpg\",grayscale=True ,target_size = (128,128))\n",
    "    image_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    image_arr = np.array([image_arr])\n",
    "    pred = SemodelImport.predict_classes(image_arr)\n",
    "    print(np.array(label)[pred])\n",
    "    out = out + (str(np.array(label)[pred]))[2]\n",
    "engine.setProperty('rate',150) #determine the rate of speech (optional)/ used for changing rate of speech\n",
    "engine.say(out) #\n",
    "engine.runAndWait() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435e521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
